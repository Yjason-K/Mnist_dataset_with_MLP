{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Part 2-11-2 MLP implementaion.ipynb",
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyOTym869fSWLLqpuXHLPJxx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Yjason-K/Mnist_dataset_with_MLP/blob/main/Part_2_11_2_MLP(Mnist_dataset).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R4xX85FpoXW3"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from numpy.random import normal\n",
        "from numpy import size\n",
        "\n",
        "from termcolor import colored\n",
        "import matplotlib.pyplot as plt\n",
        "plt.style.use('seaborn')\n",
        "\n",
        "from tensorflow.keras.datasets.mnist import load_data\n",
        "\n",
        "(train_images, train_labels), test_ds = load_data()\n",
        "print(type(train_images), type(train_labels))\n",
        "print(train_images.shape, train_labels.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#데이터 이미지 출력해보기\n",
        "view_images = train_images[:9, ...]\n",
        "print(view_images.shape)\n",
        "fig, axes = plt.subplots(3, 3, figsize=(10,10))\n",
        "for ax_idx, ax in enumerate(axes.flat):\n",
        "    image = view_images[ax_idx]\n",
        "    ax.imshow(image)"
      ],
      "metadata": {
        "id": "_5Obc3o7o2KQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#set test env.\n",
        "n_data = train_images.shape[0]\n",
        "n_feature = train_images.shape[1]*train_images.shape[2]\n",
        "b_size = 64\n",
        "n_batch = n_data // b_size\n",
        "epochs = 20\n",
        "lr = 0.03\n",
        "units = [64, 32, 10]"
      ],
      "metadata": {
        "id": "VLB_2ByMo4T1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# initalize W, B\n",
        "\n",
        "W1 = normal(0, 1, (n_feature, units[0]))\n",
        "B1 = np.zeros(units[0])\n",
        "\n",
        "W2 = normal(0, 1, (units[0], units[1]))\n",
        "B2 = np.zeros(units[1])\n",
        "\n",
        "W3 = normal(0, 1, (units[1], units[2]))\n",
        "B3 = np.zeros(units[2])\n",
        "\n",
        "print(colored(\"W/B shpes\", \"green\"))\n",
        "print(f\"W1/B1: {W1.shape}/{B1.shape}\")\n",
        "print(f\"W2/B2: {W2.shape}/{B2.shape}\")\n",
        "print(f\"W3/B3: {W3.shape}/{B3.shape}\")"
      ],
      "metadata": {
        "id": "PGIWRmYho6Tg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# losses, forward propagation, back propagation\n",
        "\n",
        "losses, accs = list(), list()\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    n_correct, n_data= 0, 0\n",
        "    for b_idx in range(n_batch):\n",
        "        start_idx = b_idx * b_size\n",
        "        end_idx = (b_idx + 1)*b_size\n",
        "        print(start_idx, end_idx)\n",
        "        images = train_images[start_idx: end_idx, ...]\n",
        "        print(images.shape)\n",
        "        X = images.reshape(b_size, -1)\n",
        "        print(X.shape)\n",
        "        \n",
        "        Y = train_labels[start_idx: end_idx]\n",
        "        print(Y.shape)\n",
        "        break\n",
        "    break"
      ],
      "metadata": {
        "id": "G08j4h83o8NM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# losses, forward propagation, back propagation\n",
        "\n",
        "losses, accs = list(), list()\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    n_correct, n_data= 0, 0\n",
        "    for b_idx in range(n_batch):\n",
        "        # get mini-batch\n",
        "        start_idx = b_idx * b_size\n",
        "        end_idx = (b_idx + 1)*b_size\n",
        "        images = train_images[start_idx: end_idx, ...]\n",
        "        \n",
        "        X = images.reshape(b_size, -1)\n",
        "        Y = train_labels[start_idx: end_idx]\n",
        "        \n",
        "        ## forward propagation\n",
        "        \n",
        "        #dense1\n",
        "        Z1 = X @ W1 + B1\n",
        "        A1 = 1/ (1 + np.exp(-Z1))\n",
        "        \n",
        "        #dense2\n",
        "        Z2 = A1 @ W2 + B2\n",
        "        A2 = 1/ (1 + np.exp(-Z2))\n",
        "        \n",
        "        #dense3\n",
        "        L = A2 @ W3 + B3\n",
        "        \n",
        "        #loss\n",
        "        Pred = np.exp(L)/ np.sum(np.exp(L), axis=1, keepdims = True)\n",
        "        J0 = -np.log(Pred[np.arange(b_size), Y]) #CCEE J0\n",
        "        print(J0.shape)\n",
        "        break\n",
        "        \n",
        "    break"
      ],
      "metadata": {
        "id": "ZPUxrlPEo_TL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# losses, forward propagation, back propagation\n",
        "\n",
        "losses, accs = list(), list()\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    n_correct, n_data= 0, 0\n",
        "    for b_idx in range(n_batch):\n",
        "        # get mini-batch\n",
        "        start_idx = b_idx * b_size\n",
        "        end_idx = (b_idx + 1)*b_size\n",
        "        images = train_images[start_idx: end_idx, ...]\n",
        "        \n",
        "        X = images.reshape(b_size, -1)\n",
        "        Y = train_labels[start_idx: end_idx]\n",
        "        \n",
        "        ## forward propagation\n",
        "        \n",
        "        #dense1\n",
        "        Z1 = X @ W1 + B1\n",
        "        A1 = 1/ (1 + np.exp(-Z1))\n",
        "        \n",
        "        #dense2\n",
        "        Z2 = A1 @ W2 + B2\n",
        "        A2 = 1/ (1 + np.exp(-Z2))\n",
        "        \n",
        "        #dense3\n",
        "        L = A2 @ W3 + B3\n",
        "        \n",
        "        #loss\n",
        "        Pred = np.exp(L)/ np.sum(np.exp(L), axis=1, keepdims = True)\n",
        "        J = np.mean(-np.log(Pred[np.arange(b_size), Y])) #CCEE\n",
        "        losses.append(J)\n",
        "        \n",
        "        # calculate accuracy\n",
        "        Pred_labels = np.argmax(Pred, axis =1)\n",
        "        n_correct += np.sum(Pred_labels == Y)\n",
        "        n_data += b_size\n",
        "        \n",
        "        #print(Pred_labels)\n",
        "        #print(Y)\n",
        "        #print(n_correct, n_data)\n",
        "        \n",
        "        ###backpropagation\n",
        "        labels = Y.copy()\n",
        "        Y = np.zeros_like(Pred)\n",
        "        Y[np.arange(b_size), labels] = 1 #one-hot encoding\n",
        "        \n",
        "        #loss\n",
        "        dL = -1/b_size*(Y - Pred)\n",
        "        #dense3\n",
        "        dA2 = dL @ W3.T\n",
        "        dW3 = A2.T @ dL\n",
        "        dB3 = np.sum(dL, axis= 0)\n",
        "        #dense2\n",
        "        dZ2 = dA2 * A2*(1-A2)\n",
        "        dA1 = dZ2 @ W2.T\n",
        "        dW2 = A1.T @ dZ2\n",
        "        dB2 = np.sum(dZ2, axis=0)\n",
        "        #dense1\n",
        "        dZ1 = dA1 * A1*(1-A1)\n",
        "        dW1 = X.T @ dZ1\n",
        "        dB1 = np.sum(dZ1, axis=0)\n",
        "        \n",
        "        #parameter update\n",
        "        W3, B3 = W3 - lr*dW3, B3 - lr*dB3\n",
        "        W2, B2 = W2 - lr*dW2, B2 - lr*dB2\n",
        "        W1, B1 = W1 - lr*dW1, B1 - lr*dB1\n",
        "        \n",
        "        #acc update\n",
        "        accs.append(n_correct/n_data)"
      ],
      "metadata": {
        "id": "hMKTmDZsqF5Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, axes = plt.subplots(2,1 , figsize=(20, 10))\n",
        "axes[0].plot(losses)\n",
        "axes[1].plot(accs)\n",
        "\n",
        "axes[0].set_title(\"Train Loss\", color='darkblue', fontsize=40)\n",
        "axes[0].set_xlabel(\"Iter Idx\", fontsize=30)\n",
        "axes[0].set_ylabel(\"CCEE\", fontsize=30)\n",
        "\n",
        "axes[1].set_title(\"Train Accuracy\", color='darkblue', fontsize=40)\n",
        "axes[1].set_xlabel(\"Epoch\", fontsize=30)\n",
        "axes[1].set_ylabel(\"Accuarcy\", fontsize=30)\n",
        "axes[1].set_yticks(np.linspace(0.4, 1.0, 7))\n",
        "\n",
        "axes[0].tick_params(labelsize=30)\n",
        "axes[1].tick_params(labelsize=30)\n",
        "fig.tight_layout()"
      ],
      "metadata": {
        "id": "v-xK-4Rm0pB5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}